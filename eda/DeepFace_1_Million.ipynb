{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5yLODhLghMa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b812c656-882d-4d95-cf5b-d47f6da54f03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 78, in main\n",
            "    command = create_command(cmd_name, isolated=(\"--isolated\" in cmd_args))\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/__init__.py\", line 114, in create_command\n",
            "    module = importlib.import_module(module_path)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 15, in <module>\n",
            "    from pip._internal.cli.req_command import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 18, in <module>\n",
            "    from pip._internal.index.collector import LinkCollector\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/index/collector.py\", line 38, in <module>\n",
            "    from pip._internal.network.session import PipSession\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/network/session.py\", line 41, in <module>\n",
            "    from pip import __version__\n",
            "  File \"<frozen importlib._bootstrap>\", line 1207, in _handle_fromlist\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install deepface"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 1 Million"
      ],
      "metadata": {
        "id": "boQr2VaRgna7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random\n",
        "from deepface import DeepFace\n",
        "import cv2\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_folder = '/content/drive/MyDrive/w210/'\n",
        "os.makedirs(drive_folder, exist_ok=True)\n",
        "csv_file = 'million_balanced.csv'\n",
        "\n",
        "drive_csv_path = os.path.join(drive_folder, csv_file)\n",
        "\n",
        "def save_to_drive():\n",
        "    shutil.copy(csv_file, drive_csv_path)\n",
        "    print(f\"Updated {csv_file} saved to Google Drive at {drive_csv_path}.\")\n",
        "\n",
        "dir = kagglehub.dataset_download(\"dullaz/1m-ai-generated-faces-128x128\")\n",
        "path = os.path.join(dir, 'fake_faces_dataset')\n",
        "\n",
        "all_files = [os.path.join(path, f) for f in os.listdir(path)]\n",
        "\n",
        "img_path_df = pd.DataFrame({\"image_path\": all_files})\n",
        "\n",
        "all_results = []\n",
        "i = 0\n",
        "white = 0\n",
        "non_white = 0\n",
        "MAX_COUNT = 39700\n",
        "MAX_PER_GROUP = MAX_COUNT // 2\n",
        "\n",
        "for img in img_path_df.image_path:\n",
        "  if white + non_white >= MAX_COUNT:\n",
        "    break\n",
        "\n",
        "  image = cv2.imread(img)\n",
        "  if image is None:\n",
        "    continue\n",
        "\n",
        "  result = DeepFace.analyze(image, actions=['age', 'gender', 'race'], enforce_detection=False)\n",
        "  if isinstance(result, list) and len(result) > 0:\n",
        "    dominant_race = result[0]['dominant_race']\n",
        "\n",
        "    if dominant_race == 'white' and white < MAX_PER_GROUP:\n",
        "      white += 1\n",
        "      result[0]['image_path'] = img\n",
        "      all_results.append(result[0])\n",
        "\n",
        "    elif dominant_race != 'white' and non_white < MAX_PER_GROUP:\n",
        "        non_white += 1\n",
        "        result[0]['image_path'] = img\n",
        "        all_results.append(result[0])\n",
        "\n",
        "    i += 1\n",
        "    print(i)\n",
        "\n",
        "pd.DataFrame(all_results).to_csv(csv_file)\n",
        "save_to_drive()\n"
      ],
      "metadata": {
        "id": "WiYFizxZgplO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random\n",
        "import cv2\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "dir = kagglehub.dataset_download(\"dullaz/1m-ai-generated-faces-128x128\")\n",
        "path = os.path.join(dir, 'fake_faces_dataset')\n",
        "\n",
        "all_files = [os.path.join(path, f) for f in os.listdir(path)]\n",
        "\n",
        "img_path_df = pd.DataFrame({\"image_path\": all_files})\n",
        "\n",
        "df = pd.read_csv(\"final_million_all_balanced.csv\")\n",
        "\n",
        "csv_path = 'final_million_all_balanced.csv'\n",
        "destination_folder = '/content/million_selected_images/'\n",
        "\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "for img_path in df['image_path']:\n",
        "    if os.path.exists(img_path):\n",
        "        shutil.copy(img_path, destination_folder)\n",
        "    else:\n",
        "        print(f\"File not found: {img_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKDfwX6z7tCq",
        "outputId": "0ba3b1bb-ca40-44fb-9769-75044939ac91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/dullaz/1m-ai-generated-faces-128x128?dataset_version_number=5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.08G/4.08G [00:46<00:00, 94.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ningyu1991/ArtificialGANFingerprints.git\n",
        "%cd ArtificialGANFingerprints\n",
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "id": "G8GhOt4yA2xR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8725643-81fb-4360-fa9a-03a809d6e561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ArtificialGANFingerprints'...\n",
            "remote: Enumerating objects: 288, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 288 (delta 6), reused 0 (delta 0), pack-reused 276 (from 1)\u001b[K\n",
            "Receiving objects: 100% (288/288), 795.03 KiB | 2.38 MiB/s, done.\n",
            "Resolving deltas: 100% (167/167), done.\n",
            "/content/ArtificialGANFingerprints\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.21.0+cu124)\n",
            "Collecting tensorboardX (from -r requirements.txt (line 4))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 3)) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 3)) (11.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardX->-r requirements.txt (line 4)) (24.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX->-r requirements.txt (line 4)) (5.29.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.txt (line 2)) (3.0.2)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ]
    }
  ]
}